{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 10: CNN\n",
    " \n",
    "## Structure\n",
    "CNN (Convolutional Neural Network)\n",
    "\n",
    "Input -> Feature Extraction (convolution + subsampling) -> Classification (fully connected, Dense Net) -> Output\n",
    "\n",
    "## Convolution\n",
    "\n",
    "Cut a small \"Patch\" from the whole data and do operations to get one value.\n",
    "\n",
    "Example) cut 3x3x1 input data with 2x2x1 filter, stride 1x1 :=> 2x2x1 data is generated \n",
    "\n",
    "\n",
    "$$\n",
    "Example =  \\begin{bmatrix}\n",
    "1 & 2 & 3\\\\\n",
    "4 & 5 & 6\\\\\n",
    "7 & 8 & 9 \n",
    "\\end{bmatrix} \n",
    ",\n",
    "Filter = \\begin{bmatrix}\n",
    "0.1 & 0.5 \\\\\n",
    "0.3 & 0.4\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Result = \\begin{bmatrix}\n",
    "4.3 & 5.6 \\\\\n",
    "8.2 & 9.5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$ ex) 1 * 0.1  + 2 * 0.5 + 4 * 0.3 + 5 * 0.4 = 4.3 , 2 * 0.1  + 3 * 0.5 + 5 * 0.3 + 6 * 0.4 = 5.6 , ... $$\n",
    "\n",
    "Usually, dot product $$ w^T x +b $$ is used.\n",
    "\n",
    "\n",
    "## ConvNet\n",
    "\n",
    "For Example, Operating with a 32px * 32px image:\n",
    "\n",
    "Each pixel has a RGB Data, so it the input data size is 32 * 32 *3.\n",
    "If we had 6 5 * 5 * 3 filters, we would get 6 seperate 28 * 28 activation maps. (28 * 28 * 6 data)\n",
    "\n",
    "ConvNet is a Sequence of Convolutional Layers, interspersed with activation functions.\n",
    "\n",
    "## Pooling\n",
    "\n",
    "Max Pooling : Choose the maximum data from a certain filter size to compress the data.\n",
    "\n",
    "Example: Max pooling with 2x2 filter and stride 2\n",
    "\n",
    "$$\n",
    "Example =  \\begin{bmatrix}\n",
    "1 & 1 & 2 & 4\\\\\n",
    "5 & 6 & 7 & 8\\\\\n",
    "3 & 2 & 1 & 0\\\\\n",
    "1 & 2 & 3 & 4 \n",
    "\\end{bmatrix} \n",
    "$$\n",
    "$$\n",
    "Result = \\begin{bmatrix}\n",
    "6 & 8 \\\\\n",
    "3 & 4\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Average Pooling : Calculate the average data from a certain filter size to compress the data.\n",
    "\n",
    "Example: Average pooling with 2x2 filter and stride 2\n",
    "\n",
    "$$\n",
    "Example =  \\begin{bmatrix}\n",
    "1 & 1 & 2 & 4\\\\\n",
    "5 & 6 & 7 & 8\\\\\n",
    "3 & 2 & 1 & 0\\\\\n",
    "1 & 2 & 3 & 4 \n",
    "\\end{bmatrix} \n",
    "$$\n",
    "$$\n",
    "Result = \\begin{bmatrix}\n",
    "3.25 & 5.25 \\\\\n",
    "2 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "## Simple CNN\n",
    "\n",
    "In CNN, Features are Localy Connected!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/9s4ycw_d3q567rb82x3f01l40000gn/T/ipykernel_4185/1610885877.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.311669\n",
      "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.291767\n",
      "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.282655\n",
      "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.253082\n",
      "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.242240\n",
      "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.186744\n",
      "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.186741\n",
      "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.129659\n",
      "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 1.998003\n",
      "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 1.854017\n",
      "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 1.616081\n",
      "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 1.318685\n",
      "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 1.103563\n",
      "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 0.916893\n",
      "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 0.808342\n",
      "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 0.658243\n",
      "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 0.722686\n",
      "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 0.522026\n",
      "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 0.784693\n",
      "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 0.805367\n",
      "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 0.407903\n",
      "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 0.568968\n",
      "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 0.462909\n",
      "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 0.499947\n",
      "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 0.462849\n",
      "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 0.471303\n",
      "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 0.563575\n",
      "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 0.756686\n",
      "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 0.375150\n",
      "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 0.544073\n",
      "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 0.386055\n",
      "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 0.356114\n",
      "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 0.319513\n",
      "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 0.538281\n",
      "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 0.506874\n",
      "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 0.392279\n",
      "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 0.340925\n",
      "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 0.764538\n",
      "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 0.215246\n",
      "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 0.246234\n",
      "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 0.403404\n",
      "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 0.644419\n",
      "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 0.240224\n",
      "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 0.272766\n",
      "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 0.333297\n",
      "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 0.285851\n",
      "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 0.157843\n",
      "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 0.210852\n",
      "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 0.222171\n",
      "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 0.246090\n",
      "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 0.232260\n",
      "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 0.421070\n",
      "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 0.389293\n",
      "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 0.206424\n",
      "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 0.245738\n",
      "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 0.247085\n",
      "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 0.333825\n",
      "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 0.222255\n",
      "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 0.188871\n",
      "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 0.288041\n",
      "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 0.370015\n",
      "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 0.236677\n",
      "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 0.212563\n",
      "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 0.322410\n",
      "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 0.151515\n",
      "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 0.122623\n",
      "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 0.212223\n",
      "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 0.127837\n",
      "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 0.200948\n",
      "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 0.251431\n",
      "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 0.113305\n",
      "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 0.269389\n",
      "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 0.298312\n",
      "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 0.227441\n",
      "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 0.262467\n",
      "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 0.092345\n",
      "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 0.071474\n",
      "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 0.208566\n",
      "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 0.186429\n",
      "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 0.156787\n",
      "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 0.162655\n",
      "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 0.151092\n",
      "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 0.167329\n",
      "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 0.246694\n",
      "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 0.132449\n",
      "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 0.256875\n",
      "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 0.194571\n",
      "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 0.125967\n",
      "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 0.282069\n",
      "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 0.168449\n",
      "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 0.258020\n",
      "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 0.146927\n",
      "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 0.236261\n",
      "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 0.267876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/9s4ycw_d3q567rb82x3f01l40000gn/T/ipykernel_4185/1610885877.py:71: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Test set: Average loss: 0.0030, Accuracy: 9435/10000 (94%)\n",
      "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 0.240005\n",
      "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 0.150401\n",
      "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 0.220948\n",
      "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 0.233398\n",
      "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 0.079008\n",
      "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 0.204159\n",
      "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 0.167351\n",
      "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 0.207240\n",
      "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 0.150037\n",
      "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 0.368356\n",
      "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 0.169885\n",
      "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 0.165576\n",
      "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 0.233635\n",
      "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 0.175475\n",
      "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 0.297763\n",
      "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 0.309790\n",
      "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 0.075527\n",
      "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.248498\n",
      "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 0.147279\n",
      "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 0.054688\n",
      "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.097848\n",
      "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.193168\n",
      "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 0.106608\n",
      "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.449044\n",
      "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.123106\n",
      "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.293653\n",
      "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.213163\n",
      "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.177140\n",
      "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.129692\n",
      "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.174279\n",
      "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.075042\n",
      "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.352548\n",
      "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.128241\n",
      "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.174197\n",
      "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.145221\n",
      "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.147326\n",
      "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.085967\n",
      "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.080793\n",
      "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.205567\n",
      "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.147181\n",
      "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.309737\n",
      "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.170718\n",
      "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.131947\n",
      "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.170179\n",
      "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.069737\n",
      "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.190663\n",
      "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.143743\n",
      "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.099266\n",
      "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.212802\n",
      "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.234804\n",
      "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.181209\n",
      "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.056603\n",
      "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.044396\n",
      "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.176486\n",
      "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.168282\n",
      "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.140757\n",
      "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.056620\n",
      "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.257720\n",
      "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.106841\n",
      "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.079715\n",
      "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.171464\n",
      "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.272437\n",
      "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.140448\n",
      "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.154536\n",
      "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.089485\n",
      "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.096541\n",
      "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.092684\n",
      "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.078252\n",
      "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.132587\n",
      "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.101834\n",
      "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.165843\n",
      "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.167575\n",
      "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.042965\n",
      "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.251513\n",
      "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.124314\n",
      "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.225386\n",
      "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.131740\n",
      "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.102880\n",
      "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.163100\n",
      "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.129643\n",
      "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.098470\n",
      "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.179119\n",
      "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.087705\n",
      "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.125473\n",
      "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.126984\n",
      "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.067031\n",
      "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.126520\n",
      "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.136257\n",
      "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.047847\n",
      "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.243483\n",
      "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.068290\n",
      "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.264338\n",
      "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.087764\n",
      "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.104631\n",
      "===========================\n",
      "Test set: Average loss: 0.0019, Accuracy: 9626/10000 (96%)\n",
      "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.044247\n",
      "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.032595\n",
      "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.107519\n",
      "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.083954\n",
      "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.357774\n",
      "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.154995\n",
      "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.059531\n",
      "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.211812\n",
      "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.135429\n",
      "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.083178\n",
      "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.127370\n",
      "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.033537\n",
      "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.123677\n",
      "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.089429\n",
      "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.133260\n",
      "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.141439\n",
      "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.295411\n",
      "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.180917\n",
      "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.050237\n",
      "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.249254\n",
      "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.123319\n",
      "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.173927\n",
      "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.062856\n",
      "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.149987\n",
      "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.027663\n",
      "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.062463\n",
      "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.101006\n",
      "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.226106\n",
      "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.220316\n",
      "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.230142\n",
      "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.121284\n",
      "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.057698\n",
      "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.136644\n",
      "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.081391\n",
      "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.079515\n",
      "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.073467\n",
      "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.107142\n",
      "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.079850\n",
      "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.045656\n",
      "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.122637\n",
      "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.070003\n",
      "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.070684\n",
      "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.060918\n",
      "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.134864\n",
      "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.090175\n",
      "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.070999\n",
      "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.038300\n",
      "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.137869\n",
      "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.084723\n",
      "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.113862\n",
      "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.082732\n",
      "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.053481\n",
      "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.099588\n",
      "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.082379\n",
      "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.177480\n",
      "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.087304\n",
      "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.227757\n",
      "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.067012\n",
      "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.078410\n",
      "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.146457\n",
      "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.112497\n",
      "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.155748\n",
      "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.077537\n",
      "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.096122\n",
      "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.112932\n",
      "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.078627\n",
      "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.029230\n",
      "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.229032\n",
      "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.043175\n",
      "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.054758\n",
      "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.085543\n",
      "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.057191\n",
      "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.068376\n",
      "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.107859\n",
      "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.128682\n",
      "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.097269\n",
      "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.118555\n",
      "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.122308\n",
      "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.168425\n",
      "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.144222\n",
      "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.551820\n",
      "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.118192\n",
      "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.095980\n",
      "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.078101\n",
      "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.102825\n",
      "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.061761\n",
      "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.122257\n",
      "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.177025\n",
      "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.186357\n",
      "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.028910\n",
      "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.162030\n",
      "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.110431\n",
      "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.064401\n",
      "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.171269\n",
      "===========================\n",
      "Test set: Average loss: 0.0015, Accuracy: 9690/10000 (97%)\n",
      "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.108683\n",
      "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.032782\n",
      "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.120055\n",
      "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.256510\n",
      "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.046949\n",
      "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.117957\n",
      "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.126806\n",
      "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.009934\n",
      "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.080977\n",
      "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.081342\n",
      "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.115864\n",
      "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.063652\n",
      "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.107479\n",
      "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.153101\n",
      "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.061972\n",
      "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.038458\n",
      "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.061221\n",
      "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.097241\n",
      "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.066649\n",
      "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.079338\n",
      "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.045650\n",
      "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.030691\n",
      "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.084335\n",
      "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.061783\n",
      "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.078910\n",
      "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.152616\n",
      "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.104959\n",
      "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.089051\n",
      "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.066488\n",
      "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.083765\n",
      "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.115850\n",
      "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.027401\n",
      "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.022988\n",
      "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.028876\n",
      "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.104197\n",
      "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.115426\n",
      "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.077320\n",
      "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.137340\n",
      "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.055809\n",
      "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.110140\n",
      "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.086917\n",
      "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.086616\n",
      "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.178911\n",
      "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.143750\n",
      "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.074085\n",
      "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.076810\n",
      "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.098840\n",
      "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.100109\n",
      "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.076679\n",
      "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.111203\n",
      "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.041179\n",
      "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.020835\n",
      "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.092320\n",
      "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.023973\n",
      "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.092104\n",
      "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.100709\n",
      "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.089931\n",
      "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.103137\n",
      "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.074564\n",
      "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.051045\n",
      "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.041887\n",
      "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.066574\n",
      "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.068737\n",
      "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.088720\n",
      "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.067615\n",
      "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.104998\n",
      "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.043718\n",
      "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.176537\n",
      "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.039296\n",
      "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.019233\n",
      "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.076235\n",
      "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.060521\n",
      "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.027440\n",
      "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.066664\n",
      "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.084051\n",
      "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.058655\n",
      "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.062953\n",
      "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.166463\n",
      "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.033758\n",
      "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.171338\n",
      "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.050812\n",
      "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.067408\n",
      "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.023634\n",
      "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.062910\n",
      "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.018314\n",
      "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.120194\n",
      "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.029394\n",
      "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.211497\n",
      "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.084767\n",
      "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.045385\n",
      "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.109095\n",
      "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.139069\n",
      "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.130232\n",
      "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.068462\n",
      "===========================\n",
      "Test set: Average loss: 0.0012, Accuracy: 9762/10000 (98%)\n",
      "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.193792\n",
      "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.033287\n",
      "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.019918\n",
      "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.159641\n",
      "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.067889\n",
      "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.062151\n",
      "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.053465\n",
      "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.033454\n",
      "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.027174\n",
      "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.042711\n",
      "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.081833\n",
      "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.079967\n",
      "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.122352\n",
      "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.070857\n",
      "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.019543\n",
      "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.035248\n",
      "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.066211\n",
      "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.238293\n",
      "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.232885\n",
      "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.201420\n",
      "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.082628\n",
      "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.056384\n",
      "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.042519\n",
      "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.280500\n",
      "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.093815\n",
      "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.040673\n",
      "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.061831\n",
      "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.111551\n",
      "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.107404\n",
      "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.041501\n",
      "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.062747\n",
      "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.072306\n",
      "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.100119\n",
      "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.084524\n",
      "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.136898\n",
      "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.173817\n",
      "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.085554\n",
      "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.107140\n",
      "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.013452\n",
      "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.064176\n",
      "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.021209\n",
      "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.092140\n",
      "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.023804\n",
      "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.134106\n",
      "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.049248\n",
      "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.066110\n",
      "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.084164\n",
      "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.111594\n",
      "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.070665\n",
      "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.071871\n",
      "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.063412\n",
      "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.029110\n",
      "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.013930\n",
      "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.129896\n",
      "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.016134\n",
      "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.044710\n",
      "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.039449\n",
      "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.066878\n",
      "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.095166\n",
      "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.030415\n",
      "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.156675\n",
      "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.009535\n",
      "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.037120\n",
      "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.060489\n",
      "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.032532\n",
      "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.053763\n",
      "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.032294\n",
      "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.041309\n",
      "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.061473\n",
      "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.023252\n",
      "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.022981\n",
      "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.014920\n",
      "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.078072\n",
      "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.041587\n",
      "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.032752\n",
      "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.079448\n",
      "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.111184\n",
      "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.056067\n",
      "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.144347\n",
      "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.102799\n",
      "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.106283\n",
      "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.037172\n",
      "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.046167\n",
      "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.031179\n",
      "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.164509\n",
      "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.045773\n",
      "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.047713\n",
      "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.025448\n",
      "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.049542\n",
      "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.090780\n",
      "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.075294\n",
      "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.052729\n",
      "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.042072\n",
      "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.046015\n",
      "===========================\n",
      "Test set: Average loss: 0.0010, Accuracy: 9792/10000 (98%)\n",
      "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.037742\n",
      "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.104834\n",
      "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.016685\n",
      "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.111743\n",
      "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.097800\n",
      "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.080941\n",
      "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.010716\n",
      "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.089930\n",
      "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.173415\n",
      "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.026923\n",
      "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.021566\n",
      "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.025337\n",
      "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.170426\n",
      "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.023511\n",
      "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.079329\n",
      "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.115893\n",
      "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.097916\n",
      "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.020475\n",
      "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.108574\n",
      "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.073994\n",
      "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.113825\n",
      "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.049265\n",
      "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.111376\n",
      "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.032104\n",
      "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.115008\n",
      "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.015932\n",
      "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.173499\n",
      "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.227604\n",
      "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.029230\n",
      "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.086596\n",
      "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.079798\n",
      "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.059992\n",
      "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.026610\n",
      "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.053588\n",
      "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.016624\n",
      "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.082527\n",
      "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.048164\n",
      "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.097847\n",
      "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.026010\n",
      "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.038364\n",
      "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.024257\n",
      "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.061948\n",
      "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.118409\n",
      "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.048789\n",
      "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.020229\n",
      "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.040158\n",
      "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.114261\n",
      "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.077561\n",
      "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.024989\n",
      "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.038252\n",
      "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.128970\n",
      "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.105929\n",
      "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.178844\n",
      "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.018566\n",
      "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.038799\n",
      "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.082289\n",
      "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.213824\n",
      "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.073707\n",
      "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.045576\n",
      "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.025867\n",
      "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.070200\n",
      "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.037792\n",
      "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.066998\n",
      "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.033837\n",
      "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.094996\n",
      "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.070080\n",
      "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.045117\n",
      "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.012981\n",
      "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.020013\n",
      "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.039906\n",
      "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.016875\n",
      "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.037208\n",
      "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.141664\n",
      "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.042967\n",
      "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.042232\n",
      "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.137488\n",
      "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.026679\n",
      "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.169465\n",
      "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.083467\n",
      "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.093367\n",
      "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.077007\n",
      "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.105194\n",
      "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.046466\n",
      "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.088441\n",
      "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.040550\n",
      "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.057737\n",
      "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.075113\n",
      "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.050833\n",
      "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.305336\n",
      "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.064294\n",
      "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.140230\n",
      "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.088292\n",
      "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.152662\n",
      "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.025501\n",
      "===========================\n",
      "Test set: Average loss: 0.0009, Accuracy: 9820/10000 (98%)\n",
      "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.269071\n",
      "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.016909\n",
      "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.014078\n",
      "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.102155\n",
      "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.032264\n",
      "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.036586\n",
      "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.143150\n",
      "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.068527\n",
      "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.091479\n",
      "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.101186\n",
      "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.067703\n",
      "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.087693\n",
      "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.208224\n",
      "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.053756\n",
      "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.002991\n",
      "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.099518\n",
      "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.217650\n",
      "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.101168\n",
      "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.028109\n",
      "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.155280\n",
      "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.090860\n",
      "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.092825\n",
      "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.017844\n",
      "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.184486\n",
      "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.007767\n",
      "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.034753\n",
      "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.065929\n",
      "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.008853\n",
      "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.062005\n",
      "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.014981\n",
      "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.013560\n",
      "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.031369\n",
      "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.060836\n",
      "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.097263\n",
      "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.153189\n",
      "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.035098\n",
      "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.036391\n",
      "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.016737\n",
      "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.015955\n",
      "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.018744\n",
      "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.033310\n",
      "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.120477\n",
      "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.051701\n",
      "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.016652\n",
      "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.094070\n",
      "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.040176\n",
      "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.065916\n",
      "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.072943\n",
      "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.089634\n",
      "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.020571\n",
      "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.036389\n",
      "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.037617\n",
      "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.023789\n",
      "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.039617\n",
      "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.032241\n",
      "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.074475\n",
      "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.177319\n",
      "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.052766\n",
      "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.125766\n",
      "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.091520\n",
      "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.049362\n",
      "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.133210\n",
      "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.081973\n",
      "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.053013\n",
      "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.070543\n",
      "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.030969\n",
      "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.041036\n",
      "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.101505\n",
      "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.128964\n",
      "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.009996\n",
      "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.088329\n",
      "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.065202\n",
      "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.012717\n",
      "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.011696\n",
      "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.096257\n",
      "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.333588\n",
      "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.104970\n",
      "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.038926\n",
      "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.036810\n",
      "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.010485\n",
      "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.036529\n",
      "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.070021\n",
      "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.033508\n",
      "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.023072\n",
      "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.075764\n",
      "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.143095\n",
      "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.077890\n",
      "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.159227\n",
      "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.029056\n",
      "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.104525\n",
      "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.035765\n",
      "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.043345\n",
      "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.042952\n",
      "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.076222\n",
      "===========================\n",
      "Test set: Average loss: 0.0008, Accuracy: 9829/10000 (98%)\n",
      "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.026451\n",
      "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.025067\n",
      "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.155183\n",
      "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.042524\n",
      "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.058982\n",
      "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.046602\n",
      "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.066194\n",
      "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.079705\n",
      "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.107755\n",
      "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.042098\n",
      "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.050406\n",
      "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.021626\n",
      "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.070841\n",
      "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.063885\n",
      "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.171973\n",
      "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.017938\n",
      "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.147423\n",
      "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.032163\n",
      "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.104850\n",
      "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.044843\n",
      "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.031803\n",
      "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.049102\n",
      "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.039107\n",
      "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.009429\n",
      "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.024630\n",
      "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.027386\n",
      "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.050332\n",
      "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.052790\n",
      "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.059895\n",
      "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.018859\n",
      "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.019053\n",
      "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.113002\n",
      "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.020846\n",
      "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.081111\n",
      "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.128827\n",
      "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.089426\n",
      "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.106974\n",
      "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.038442\n",
      "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.007122\n",
      "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.042983\n",
      "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.070959\n",
      "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.021994\n",
      "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.184421\n",
      "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.047418\n",
      "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.015295\n",
      "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.020885\n",
      "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.016078\n",
      "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.038504\n",
      "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.058529\n",
      "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.029388\n",
      "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.099319\n",
      "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.061238\n",
      "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.039345\n",
      "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.041667\n",
      "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.052614\n",
      "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.107479\n",
      "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.092697\n",
      "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.066222\n",
      "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.090245\n",
      "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.080511\n",
      "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.008274\n",
      "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.100056\n",
      "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.010412\n",
      "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.037340\n",
      "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.042153\n",
      "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.015821\n",
      "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.080700\n",
      "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.011385\n",
      "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.010640\n",
      "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.015553\n",
      "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.053903\n",
      "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.017516\n",
      "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.075233\n",
      "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.064632\n",
      "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.139480\n",
      "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.009422\n",
      "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.026375\n",
      "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.048275\n",
      "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.022629\n",
      "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.032555\n",
      "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.068743\n",
      "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.039416\n",
      "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.020949\n",
      "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.028460\n",
      "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.164703\n",
      "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.059185\n",
      "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.100501\n",
      "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.035878\n",
      "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.020526\n",
      "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.144023\n",
      "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.138307\n",
      "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.030505\n",
      "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.012532\n",
      "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.020872\n",
      "===========================\n",
      "Test set: Average loss: 0.0007, Accuracy: 9847/10000 (98%)\n",
      "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.075969\n",
      "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.123323\n",
      "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.016887\n",
      "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.101660\n",
      "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.020633\n",
      "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.256736\n",
      "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.023537\n",
      "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.066749\n",
      "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.012994\n",
      "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.095696\n",
      "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.113247\n",
      "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.139463\n",
      "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.048733\n",
      "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.024184\n",
      "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.066827\n",
      "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.091387\n",
      "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.043857\n",
      "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.058152\n",
      "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.067891\n",
      "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.013494\n",
      "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.068504\n",
      "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.175096\n",
      "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.021128\n",
      "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.081960\n",
      "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.068983\n",
      "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.035930\n",
      "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.022251\n",
      "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.010522\n",
      "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.014088\n",
      "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.085486\n",
      "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.007084\n",
      "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.076167\n",
      "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.089075\n",
      "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.022374\n",
      "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.036832\n",
      "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.058178\n",
      "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.097876\n",
      "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.057754\n",
      "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.006661\n",
      "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.057083\n",
      "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.053586\n",
      "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.040455\n",
      "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.117838\n",
      "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.032586\n",
      "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.029928\n",
      "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.021606\n",
      "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.160393\n",
      "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.089189\n",
      "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.045391\n",
      "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.133917\n",
      "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.086526\n",
      "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.112420\n",
      "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.062928\n",
      "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.012971\n",
      "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.064200\n",
      "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.013509\n",
      "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.104686\n",
      "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.034401\n",
      "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.065154\n",
      "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.009330\n",
      "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.031652\n",
      "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.069672\n",
      "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.046410\n",
      "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.011855\n",
      "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.062428\n",
      "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.175792\n",
      "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.091899\n",
      "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.053665\n",
      "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.019818\n",
      "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.025773\n",
      "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.106649\n",
      "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.027388\n",
      "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.007395\n",
      "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.031695\n",
      "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.119146\n",
      "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.055796\n",
      "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.009651\n",
      "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.012694\n",
      "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.130183\n",
      "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.042039\n",
      "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.019950\n",
      "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.086265\n",
      "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.162083\n",
      "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.156313\n",
      "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.200509\n",
      "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.139958\n",
      "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.104264\n",
      "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.061543\n",
      "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.082690\n",
      "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.089738\n",
      "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.005688\n",
      "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.044972\n",
      "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.170744\n",
      "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.053854\n",
      "===========================\n",
      "Test set: Average loss: 0.0007, Accuracy: 9854/10000 (99%)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# Training Settings\n",
    "batch_size=64\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "# Model Design\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super (Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "\n",
    "        self.fc = nn.Linear(320 , 10) # 320 -> 10\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = F.relu(self.mp(self.conv1(x)))\n",
    "        x = F.relu(self.mp(self.conv2(x)))\n",
    "        x = x.view(in_size, -1) # Flatten the tnesor\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "model = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        # get the index of the max log-porbability\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    train(epoch)\n",
    "    test()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
