{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 9: Softmax Classifier\n",
    "\n",
    "Consider a situation classifing into n classes.\n",
    "To make n outputs, we need to use a m x n matrix!\n",
    "How do we change to n outputs to probability?\n",
    "\n",
    "## Softmax\n",
    "\n",
    "$$ \\sigma (z)_j = \\frac {e^{z_j}}{ \\sum_{k=1}^{K} e^{z_k} }  (j =1, 2, ..., K) $$\n",
    "\n",
    "X -> Linear Model -> Scores (Logits) -> SoftMax -> Probabilities (Choose highest for prediction)\n",
    "\n",
    "## Cost Function: cross entropy\n",
    "\n",
    "$$ D(\\hat{Y}, Y) = -Ylog\\hat{Y} $$\n",
    "$$ Loss = \\frac {1}{N} \\sum_ D(s(wx_i +b) (= \\hat{y}), y_i) $$\n",
    "\n",
    "## Implementation using PyTorch\n",
    "\n",
    "When using CrossEntropyLoss, Y_pred are logits(Not Softmax), and Y are Class (Not One-hot encoded Values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Loss1 =  tensor(0.4966) \n",
      "PyTorch Loss2= tensor(1.2389)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Softmax + CrossEntropy (logSoftmax + NLLLoss)\n",
    "loss =nn.CrossEntropyLoss()\n",
    "\n",
    "# target is of size nBatch\n",
    "# each Element in target has to have 0 <= value <= nClasses (0-2)\n",
    "Y = Variable(torch.LongTensor([2,0,1]), requires_grad = False)\n",
    "\n",
    "#input is of size nBatch x nClasses = 1x4\n",
    "# Y_pred are logits (not softmax)\n",
    "Y_pred1= Variable(torch.Tensor([[0.1, 0.2, 0.9],\n",
    "                                [1.1, 0.1, 0.2],\n",
    "                                [0.2, 2.1, 0.1]]))\n",
    "Y_pred2= Variable(torch.Tensor([[0.8, 0.2, 0.3],\n",
    "                                [0.2,0.3,0.5],\n",
    "                                [0.2,0.2,0.5]]))\n",
    "\n",
    "l1 = loss(Y_pred1, Y)\n",
    "l2= loss(Y_pred2, Y)\n",
    "\n",
    "print(\"PyTorch Loss1 = \", l1.data,\n",
    "    \"\\nPyTorch Loss2=\", l2.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Softmax Classifier on MNIST\n",
    "\n",
    "## Model Design\n",
    "\n",
    "Input : 28 * 28 pixel image data\n",
    "Input Layer (784) -> Hidden Layers -> Output Layer (10)\n",
    "\n",
    "## Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.301126\n",
      "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.310943\n",
      "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.310502\n",
      "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.312083\n",
      "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.300453\n",
      "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.299345\n",
      "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.301799\n",
      "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.299917\n",
      "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 2.307039\n",
      "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 2.302605\n",
      "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 2.300593\n",
      "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 2.294588\n",
      "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 2.301765\n",
      "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 2.302658\n",
      "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 2.301330\n",
      "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 2.301408\n",
      "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 2.300803\n",
      "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 2.286702\n",
      "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 2.295118\n",
      "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 2.305908\n",
      "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 2.290844\n",
      "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 2.296952\n",
      "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 2.293563\n",
      "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 2.296906\n",
      "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 2.289784\n",
      "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 2.292960\n",
      "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 2.296237\n",
      "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 2.290161\n",
      "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 2.282371\n",
      "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 2.287641\n",
      "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 2.300897\n",
      "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 2.294281\n",
      "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 2.289624\n",
      "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 2.288384\n",
      "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 2.283942\n",
      "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 2.289743\n",
      "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 2.282321\n",
      "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 2.278018\n",
      "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 2.279420\n",
      "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 2.291400\n",
      "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 2.289150\n",
      "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 2.279319\n",
      "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 2.272563\n",
      "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 2.291981\n",
      "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 2.277393\n",
      "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 2.285169\n",
      "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 2.261227\n",
      "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 2.279660\n",
      "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 2.274913\n",
      "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 2.277323\n",
      "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 2.278352\n",
      "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 2.254677\n",
      "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 2.261999\n",
      "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 2.252777\n",
      "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 2.263683\n",
      "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 2.263083\n",
      "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 2.265808\n",
      "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 2.259891\n",
      "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 2.250808\n",
      "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 2.236067\n",
      "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 2.245891\n",
      "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 2.232412\n",
      "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 2.232638\n",
      "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 2.232533\n",
      "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 2.216538\n",
      "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 2.234337\n",
      "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 2.192381\n",
      "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 2.185112\n",
      "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 2.184728\n",
      "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 2.193296\n",
      "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 2.126634\n",
      "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 2.138025\n",
      "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 2.141340\n",
      "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 2.168300\n",
      "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 2.112144\n",
      "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 2.086047\n",
      "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 2.096275\n",
      "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 2.081640\n",
      "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 1.958089\n",
      "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 1.926869\n",
      "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 1.948006\n",
      "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 1.954041\n",
      "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 1.917055\n",
      "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 1.852276\n",
      "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 1.863701\n",
      "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 1.713361\n",
      "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 1.843148\n",
      "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 1.729983\n",
      "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 1.777115\n",
      "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 1.579852\n",
      "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 1.728784\n",
      "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 1.681790\n",
      "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 1.543100\n",
      "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 1.416743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/9s4ycw_d3q567rb82x3f01l40000gn/T/ipykernel_2864/529761606.py:71: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Test set: Average loss: 0.0234, Accuracy: 5420/10000 (54%)\n",
      "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 1.518718\n",
      "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 1.396291\n",
      "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 1.421184\n",
      "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 1.447849\n",
      "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 1.606114\n",
      "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 1.279867\n",
      "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 1.189844\n",
      "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 1.474188\n",
      "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 1.390773\n",
      "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 1.167181\n",
      "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 1.178540\n",
      "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 1.192511\n",
      "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 1.111317\n",
      "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 1.171095\n",
      "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 1.081861\n",
      "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 1.096538\n",
      "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 1.050964\n",
      "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.908276\n",
      "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 1.058185\n",
      "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 1.086606\n",
      "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.881101\n",
      "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.865342\n",
      "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 0.743579\n",
      "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.650053\n",
      "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.813196\n",
      "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.732785\n",
      "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.816525\n",
      "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.641195\n",
      "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.733063\n",
      "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.911877\n",
      "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.571907\n",
      "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.664282\n",
      "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.745016\n",
      "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.724821\n",
      "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.656863\n",
      "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.770482\n",
      "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.859778\n",
      "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.670580\n",
      "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.549743\n",
      "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.567250\n",
      "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.723523\n",
      "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.490192\n",
      "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.565827\n",
      "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.633372\n",
      "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.820639\n",
      "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.487907\n",
      "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.598732\n",
      "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.373043\n",
      "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.379455\n",
      "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.434983\n",
      "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.448128\n",
      "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.534006\n",
      "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.475139\n",
      "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.420043\n",
      "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.561071\n",
      "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.754366\n",
      "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.656924\n",
      "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.457776\n",
      "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.544322\n",
      "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.369079\n",
      "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.383531\n",
      "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.344733\n",
      "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.653982\n",
      "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.443447\n",
      "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.455475\n",
      "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.629290\n",
      "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.453501\n",
      "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.576661\n",
      "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.833975\n",
      "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.670861\n",
      "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.486315\n",
      "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.342202\n",
      "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.588573\n",
      "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.484535\n",
      "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.319266\n",
      "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.578036\n",
      "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.306551\n",
      "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.330773\n",
      "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.525719\n",
      "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.504703\n",
      "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.424914\n",
      "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.332021\n",
      "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.433767\n",
      "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.600734\n",
      "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.469923\n",
      "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.207734\n",
      "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.639243\n",
      "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.437086\n",
      "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.269889\n",
      "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.401174\n",
      "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.613474\n",
      "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.286610\n",
      "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.460561\n",
      "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.393328\n",
      "===========================\n",
      "Test set: Average loss: 0.0063, Accuracy: 8799/10000 (88%)\n",
      "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.573698\n",
      "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.403376\n",
      "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.369940\n",
      "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.367608\n",
      "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.584781\n",
      "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.536646\n",
      "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.503984\n",
      "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.331650\n",
      "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.572889\n",
      "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.302700\n",
      "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.424055\n",
      "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.460595\n",
      "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.596428\n",
      "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.333284\n",
      "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.238552\n",
      "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.403973\n",
      "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.369062\n",
      "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.456950\n",
      "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.529284\n",
      "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.353214\n",
      "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.319252\n",
      "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.322439\n",
      "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.445134\n",
      "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.322893\n",
      "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.360062\n",
      "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.325748\n",
      "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.372373\n",
      "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.234966\n",
      "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.216673\n",
      "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.481047\n",
      "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.380180\n",
      "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.236913\n",
      "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.620408\n",
      "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.418493\n",
      "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.353753\n",
      "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.490067\n",
      "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.405573\n",
      "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.356289\n",
      "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.450934\n",
      "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.505847\n",
      "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.291752\n",
      "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.348775\n",
      "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.297439\n",
      "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.421441\n",
      "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.114979\n",
      "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.465384\n",
      "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.269155\n",
      "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.276070\n",
      "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.489762\n",
      "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.220889\n",
      "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.292099\n",
      "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.288252\n",
      "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.309458\n",
      "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.402708\n",
      "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.607932\n",
      "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.440382\n",
      "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.320500\n",
      "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.269726\n",
      "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.313661\n",
      "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.361799\n",
      "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.471976\n",
      "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.299866\n",
      "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.610769\n",
      "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.564717\n",
      "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.378739\n",
      "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.346629\n",
      "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.680625\n",
      "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.280089\n",
      "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.393842\n",
      "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.311223\n",
      "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.294322\n",
      "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.400420\n",
      "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.232509\n",
      "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.360563\n",
      "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.383413\n",
      "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.173925\n",
      "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.399895\n",
      "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.344313\n",
      "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.566005\n",
      "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.257554\n",
      "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.186555\n",
      "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.359704\n",
      "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.256077\n",
      "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.457550\n",
      "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.284312\n",
      "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.389350\n",
      "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.394055\n",
      "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.322176\n",
      "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.236842\n",
      "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.260255\n",
      "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.364314\n",
      "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.471742\n",
      "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.381772\n",
      "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.270109\n",
      "===========================\n",
      "Test set: Average loss: 0.0047, Accuracy: 9125/10000 (91%)\n",
      "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.200160\n",
      "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.291616\n",
      "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.430883\n",
      "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.198800\n",
      "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.285738\n",
      "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.240443\n",
      "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.186828\n",
      "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.287928\n",
      "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.360120\n",
      "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.283873\n",
      "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.396417\n",
      "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.361165\n",
      "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.182208\n",
      "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.436478\n",
      "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.161940\n",
      "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.414835\n",
      "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.231049\n",
      "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.222294\n",
      "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.224006\n",
      "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.323516\n",
      "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.305900\n",
      "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.285904\n",
      "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.377475\n",
      "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.166457\n",
      "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.340099\n",
      "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.472836\n",
      "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.380523\n",
      "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.252098\n",
      "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.306322\n",
      "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.160498\n",
      "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.370198\n",
      "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.285295\n",
      "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.235767\n",
      "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.344786\n",
      "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.261234\n",
      "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.208757\n",
      "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.220657\n",
      "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.397075\n",
      "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.311912\n",
      "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.143102\n",
      "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.267267\n",
      "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.227606\n",
      "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.198101\n",
      "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.115546\n",
      "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.374647\n",
      "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.195212\n",
      "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.170091\n",
      "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.384845\n",
      "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.202046\n",
      "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.313989\n",
      "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.175171\n",
      "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.143715\n",
      "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.604755\n",
      "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.152850\n",
      "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.314965\n",
      "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.294426\n",
      "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.337930\n",
      "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.301105\n",
      "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.115481\n",
      "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.468311\n",
      "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.428450\n",
      "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.445888\n",
      "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.279935\n",
      "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.456351\n",
      "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.186722\n",
      "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.267807\n",
      "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.470576\n",
      "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.126558\n",
      "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.161595\n",
      "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.297428\n",
      "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.122281\n",
      "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.215672\n",
      "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.150244\n",
      "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.244004\n",
      "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.151794\n",
      "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.363433\n",
      "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.479293\n",
      "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.157372\n",
      "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.125220\n",
      "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.495201\n",
      "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.134277\n",
      "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.159526\n",
      "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.321334\n",
      "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.279757\n",
      "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.141961\n",
      "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.133064\n",
      "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.219315\n",
      "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.627643\n",
      "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.116763\n",
      "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.193475\n",
      "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.185062\n",
      "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.258374\n",
      "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.126933\n",
      "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.096402\n",
      "===========================\n",
      "Test set: Average loss: 0.0035, Accuracy: 9325/10000 (93%)\n",
      "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.151418\n",
      "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.306661\n",
      "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.241025\n",
      "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.402831\n",
      "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.300876\n",
      "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.149231\n",
      "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.062594\n",
      "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.182875\n",
      "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.306419\n",
      "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.248661\n",
      "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.385988\n",
      "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.250240\n",
      "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.069520\n",
      "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.387827\n",
      "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.296317\n",
      "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.171614\n",
      "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.212191\n",
      "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.082659\n",
      "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.207007\n",
      "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.332128\n",
      "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.378977\n",
      "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.160128\n",
      "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.132991\n",
      "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.107012\n",
      "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.325137\n",
      "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.335726\n",
      "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.117840\n",
      "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.215152\n",
      "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.199361\n",
      "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.122918\n",
      "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.105458\n",
      "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.087087\n",
      "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.195737\n",
      "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.162344\n",
      "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.415026\n",
      "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.257637\n",
      "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.230694\n",
      "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.224165\n",
      "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.377617\n",
      "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.239570\n",
      "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.284641\n",
      "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.330870\n",
      "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.157425\n",
      "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.190581\n",
      "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.124612\n",
      "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.095512\n",
      "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.115519\n",
      "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.151897\n",
      "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.261968\n",
      "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.150006\n",
      "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.124662\n",
      "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.251233\n",
      "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.112867\n",
      "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.155658\n",
      "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.155318\n",
      "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.130829\n",
      "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.193910\n",
      "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.242271\n",
      "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.172174\n",
      "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.202738\n",
      "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.173646\n",
      "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.147339\n",
      "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.058226\n",
      "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.246098\n",
      "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.279986\n",
      "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.121025\n",
      "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.082377\n",
      "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.047790\n",
      "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.058572\n",
      "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.242871\n",
      "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.237150\n",
      "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.318226\n",
      "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.248963\n",
      "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.084582\n",
      "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.238669\n",
      "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.359822\n",
      "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.334813\n",
      "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.180294\n",
      "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.304798\n",
      "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.106794\n",
      "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.104435\n",
      "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.061457\n",
      "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.125355\n",
      "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.195548\n",
      "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.097592\n",
      "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.193680\n",
      "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.229225\n",
      "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.162408\n",
      "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.128244\n",
      "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.159344\n",
      "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.131496\n",
      "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.144905\n",
      "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.161365\n",
      "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.311148\n",
      "===========================\n",
      "Test set: Average loss: 0.0029, Accuracy: 9441/10000 (94%)\n",
      "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.340602\n",
      "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.083489\n",
      "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.078840\n",
      "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.155964\n",
      "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.210894\n",
      "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.133406\n",
      "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.210032\n",
      "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.380937\n",
      "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.191915\n",
      "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.225533\n",
      "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.132228\n",
      "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.142943\n",
      "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.185516\n",
      "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.152193\n",
      "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.218172\n",
      "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.165819\n",
      "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.257485\n",
      "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.147918\n",
      "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.291832\n",
      "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.209589\n",
      "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.207562\n",
      "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.073636\n",
      "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.134762\n",
      "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.337871\n",
      "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.237472\n",
      "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.125773\n",
      "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.082657\n",
      "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.081852\n",
      "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.167879\n",
      "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.055637\n",
      "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.135823\n",
      "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.077672\n",
      "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.146031\n",
      "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.102127\n",
      "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.221740\n",
      "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.143601\n",
      "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.175606\n",
      "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.113424\n",
      "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.275857\n",
      "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.220699\n",
      "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.147089\n",
      "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.409045\n",
      "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.156494\n",
      "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.148043\n",
      "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.232990\n",
      "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.027492\n",
      "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.130002\n",
      "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.302655\n",
      "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.113512\n",
      "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.255339\n",
      "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.071812\n",
      "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.359842\n",
      "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.164479\n",
      "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.251652\n",
      "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.151171\n",
      "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.052146\n",
      "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.079018\n",
      "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.124095\n",
      "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.119186\n",
      "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.068585\n",
      "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.128111\n",
      "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.111704\n",
      "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.063652\n",
      "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.055141\n",
      "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.377882\n",
      "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.055134\n",
      "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.113759\n",
      "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.100817\n",
      "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.169607\n",
      "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.243120\n",
      "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.095175\n",
      "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.429158\n",
      "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.113950\n",
      "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.155825\n",
      "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.176999\n",
      "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.093250\n",
      "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.142693\n",
      "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.191313\n",
      "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.084161\n",
      "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.141070\n",
      "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.047123\n",
      "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.100309\n",
      "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.221788\n",
      "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.129740\n",
      "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.232403\n",
      "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.097631\n",
      "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.165914\n",
      "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.132373\n",
      "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.061108\n",
      "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.232023\n",
      "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.144939\n",
      "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.077229\n",
      "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.215910\n",
      "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.074177\n",
      "===========================\n",
      "Test set: Average loss: 0.0023, Accuracy: 9581/10000 (96%)\n",
      "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.078620\n",
      "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.217543\n",
      "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.167180\n",
      "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.083284\n",
      "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.058760\n",
      "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.094435\n",
      "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.163241\n",
      "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.349091\n",
      "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.156515\n",
      "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.092385\n",
      "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.200201\n",
      "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.145981\n",
      "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.125328\n",
      "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.145518\n",
      "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.053500\n",
      "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.120899\n",
      "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.346823\n",
      "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.167688\n",
      "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.066341\n",
      "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.062855\n",
      "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.105207\n",
      "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.190196\n",
      "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.199048\n",
      "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.255701\n",
      "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.103074\n",
      "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.127000\n",
      "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.083391\n",
      "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.104788\n",
      "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.134791\n",
      "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.205320\n",
      "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.072743\n",
      "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.072398\n",
      "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.155453\n",
      "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.120759\n",
      "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.105625\n",
      "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.105771\n",
      "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.212287\n",
      "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.166702\n",
      "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.185646\n",
      "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.145266\n",
      "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.140931\n",
      "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.072437\n",
      "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.349880\n",
      "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.089589\n",
      "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.166196\n",
      "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.065041\n",
      "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.049823\n",
      "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.156599\n",
      "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.153864\n",
      "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.086911\n",
      "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.122548\n",
      "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.049391\n",
      "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.192873\n",
      "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.056361\n",
      "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.069051\n",
      "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.120397\n",
      "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.045200\n",
      "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.099858\n",
      "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.735318\n",
      "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.071715\n",
      "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.073050\n",
      "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.062299\n",
      "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.135998\n",
      "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.089973\n",
      "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.169162\n",
      "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.036073\n",
      "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.177233\n",
      "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.203536\n",
      "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.132991\n",
      "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.050575\n",
      "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.221254\n",
      "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.135547\n",
      "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.160219\n",
      "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.119893\n",
      "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.114872\n",
      "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.145216\n",
      "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.132430\n",
      "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.037041\n",
      "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.099400\n",
      "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.100529\n",
      "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.061293\n",
      "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.255522\n",
      "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.161442\n",
      "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.044796\n",
      "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.096589\n",
      "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.091769\n",
      "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.145627\n",
      "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.068987\n",
      "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.078835\n",
      "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.183874\n",
      "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.106817\n",
      "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.028934\n",
      "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.138463\n",
      "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.152640\n",
      "===========================\n",
      "Test set: Average loss: 0.0020, Accuracy: 9626/10000 (96%)\n",
      "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.114644\n",
      "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.053904\n",
      "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.140821\n",
      "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.104278\n",
      "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.223117\n",
      "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.050376\n",
      "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.178121\n",
      "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.182632\n",
      "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.103387\n",
      "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.050076\n",
      "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.081727\n",
      "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.099972\n",
      "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.062799\n",
      "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.137025\n",
      "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.084814\n",
      "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.084321\n",
      "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.293159\n",
      "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.250257\n",
      "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.118214\n",
      "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.149599\n",
      "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.097624\n",
      "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.147715\n",
      "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.132930\n",
      "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.039369\n",
      "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.078485\n",
      "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.097945\n",
      "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.077817\n",
      "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.236150\n",
      "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.064848\n",
      "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.056799\n",
      "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.155473\n",
      "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.177596\n",
      "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.126085\n",
      "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.172580\n",
      "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.040989\n",
      "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.280420\n",
      "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.122315\n",
      "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.111839\n",
      "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.030389\n",
      "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.062291\n",
      "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.102729\n",
      "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.041614\n",
      "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.038280\n",
      "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.053198\n",
      "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.204451\n",
      "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.129877\n",
      "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.096250\n",
      "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.054891\n",
      "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.131507\n",
      "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.145747\n",
      "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.066764\n",
      "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.023737\n",
      "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.149860\n",
      "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.167690\n",
      "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.059521\n",
      "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.123091\n",
      "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.109737\n",
      "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.047589\n",
      "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.042253\n",
      "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.088806\n",
      "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.073382\n",
      "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.281950\n",
      "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.114325\n",
      "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.131050\n",
      "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.238886\n",
      "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.096534\n",
      "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.048029\n",
      "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.075674\n",
      "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.072352\n",
      "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.070633\n",
      "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.018081\n",
      "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.112433\n",
      "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.149973\n",
      "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.089612\n",
      "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.114301\n",
      "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.107767\n",
      "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.204661\n",
      "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.102121\n",
      "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.083486\n",
      "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.123158\n",
      "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.020518\n",
      "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.142139\n",
      "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.157742\n",
      "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.090666\n",
      "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.072371\n",
      "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.054151\n",
      "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.193746\n",
      "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.077374\n",
      "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.038123\n",
      "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.168435\n",
      "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.248678\n",
      "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.100591\n",
      "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.298867\n",
      "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.104934\n",
      "===========================\n",
      "Test set: Average loss: 0.0018, Accuracy: 9661/10000 (97%)\n",
      "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.089784\n",
      "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.176097\n",
      "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.136106\n",
      "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.046084\n",
      "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.039165\n",
      "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.132845\n",
      "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.053192\n",
      "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.092056\n",
      "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.024679\n",
      "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.089085\n",
      "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.054828\n",
      "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.144064\n",
      "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.050952\n",
      "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.096883\n",
      "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.127035\n",
      "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.042883\n",
      "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.061685\n",
      "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.060918\n",
      "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.153105\n",
      "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.068759\n",
      "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.072443\n",
      "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.086680\n",
      "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.175562\n",
      "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.067973\n",
      "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.121309\n",
      "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.078100\n",
      "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.085386\n",
      "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.177134\n",
      "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.179134\n",
      "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.033022\n",
      "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.066095\n",
      "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.169775\n",
      "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.088417\n",
      "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.047778\n",
      "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.039029\n",
      "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.236260\n",
      "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.121888\n",
      "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.111917\n",
      "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.218834\n",
      "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.213694\n",
      "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.110555\n",
      "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.052983\n",
      "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.067010\n",
      "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.032200\n",
      "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.100246\n",
      "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.148637\n",
      "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.084126\n",
      "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.096971\n",
      "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.087015\n",
      "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.134786\n",
      "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.031791\n",
      "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.107902\n",
      "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.049754\n",
      "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.054378\n",
      "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.063377\n",
      "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.036407\n",
      "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.052196\n",
      "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.133583\n",
      "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.057245\n",
      "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.069766\n",
      "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.063832\n",
      "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.055545\n",
      "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.064786\n",
      "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.105477\n",
      "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.234063\n",
      "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.089790\n",
      "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.189441\n",
      "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.027582\n",
      "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.164715\n",
      "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.272523\n",
      "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.061943\n",
      "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.369591\n",
      "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.032570\n",
      "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.076035\n",
      "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.086610\n",
      "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.187997\n",
      "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.132565\n",
      "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.132504\n",
      "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.120989\n",
      "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.150955\n",
      "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.123917\n",
      "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.097745\n",
      "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.062500\n",
      "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.108767\n",
      "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.053757\n",
      "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.054354\n",
      "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.060952\n",
      "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.158232\n",
      "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.031871\n",
      "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.441466\n",
      "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.109861\n",
      "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.181794\n",
      "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.129435\n",
      "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.162174\n",
      "===========================\n",
      "Test set: Average loss: 0.0018, Accuracy: 9651/10000 (97%)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# Training Settings\n",
    "batch_size=64\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "# Model Design\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1=nn.Linear(784,520)\n",
    "        self.l2=nn.Linear(520,320)\n",
    "        self.l3=nn.Linear(320,240)\n",
    "        self.l4=nn.Linear(240,120)\n",
    "        self.l5=nn.Linear(120,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flaten the data (n,1,28,28) -> (n,784)\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x) #No need activation\n",
    "\n",
    "model = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        # get the index of the max log-porbability\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
